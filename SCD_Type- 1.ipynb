{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c61e8dc-61c4-452d-a319-f8c181220082",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Variable Declarartion"
    }
   },
   "outputs": [],
   "source": [
    "SourceTable='workspace.de_practice_source.sales'\n",
    "TargetTable='workspace.de_practice_target.sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dfe1548-fd6f-4af6-9395-8f7d22ef8e04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SourceDf=spark.read.table(SourceTable)  # Read source table into DataFrame\n",
    "TargetDf=spark.read.table(TargetTable)  # Read target table into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b52a488-c51f-4eb6-8386-c18b944340a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filter the DataFrame to show only rows where 'franchiseID' is '3000001'\n",
    "# Display the filtered DataFrame for inspection\n",
    "SourceDf.filter(col(\"franchiseID\") == \"3000001\").display()\n",
    "\n",
    "# The 'city' value for rows with 'franchiseID' 3000001 is 'Tokyo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1afd5743-1589-4863-932d-9fd3864ff7d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Update the 'city' column in SourceDf:\n",
    "# For rows where 'franchiseID' equals '3000001', set the 'city' value to 'Tokyo Modified'.\n",
    "# For all other rows, retain the original 'city' value.\n",
    "SourceDf = SourceDf.withColumn(\n",
    "    \"city\",\n",
    "    when(col(\"franchiseID\") == \"3000001\", \"Delhi\").otherwise(col(\"city\"))\n",
    ")\n",
    "\n",
    "# Display rows where 'franchiseID' is '3000001' to verify the 'city' column update.\n",
    "SourceDf.filter(col(\"franchiseID\") == \"3000001\").display()\n",
    "\n",
    "# After this update, the 'city' value for all rows with 'franchiseID' 3000001 will be 'Delhi'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d463ad8d-6eb2-43c4-bb10-fb8025dc2f7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a hash key by concatenating all columns into a single string column 'RowHash'\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Concatenate all columns in 'source' DataFrame into 'RowHash'\n",
    "SourceDf = SourceDf.withColumn('RowHash', F.concat_ws('', *SourceDf.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80ff20a6-e407-4c9b-afe6-76372a17ad57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Add three new columns to SourceDf:\n",
    "# 1. 'IndCurrent': Set to 1 for all rows, indicating the current/active record.\n",
    "# 2. 'CreatedDate': Set to the current timestamp, representing when the record was created.\n",
    "# 3. 'ModifiedDate': Set to the current timestamp, representing when the record was last modified.\n",
    "SourceDf = SourceDf.withColumn(\"IndCurrent\", F.lit(1)) \\\n",
    "    .withColumn(\"CreatedDate\", F.current_timestamp()) \\\n",
    "    .withColumn(\"ModifiedDate\", F.current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ac8d2e1-fcf0-4745-831e-0039c7a52b7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SourceDf.filter(col(\"franchiseID\") == \"3000001\").display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e8ac639-8799-4ca6-96e0-56c2b8dbd9a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## ðŸ“˜ What is SCD Type 1?\n",
    "\n",
    "**SCD (Slowly Changing Dimension) Type 1** is a technique used in data warehousing to handle changes in dimension data **without preserving historical records**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ Scenario Example:\n",
    "\n",
    "- **Primary Key:** `frinsied_id`\n",
    "- **Changed Attribute:** `city`\n",
    "\n",
    "If a record with `frinsied_id = 3000001` originally had `city = 'Tokyo'`, and later the city is updated to `city = 'Delhi'`, **SCD Type 1** will simply **overwrite** the old value:\n",
    "\n",
    "| frinsied_id | city   |\n",
    "|-------------|--------|\n",
    "| 3000001         | Delhi  |\n",
    "\n",
    "> The original value `'Tokyo'` is lost â€” **no history is maintained**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¹ Key Characteristics:\n",
    "- Updates data **in place**.\n",
    "- Update `Modified Date` .\n",
    "- **No audit trail** or history of prior values.\n",
    "- Ensures the table always shows the **most recent information**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“„ Supporting Document:\n",
    "- [Microsoft Docs â€“ Slowly Changing Dimensions (SCD)](https://learn.microsoft.com/en-us/azure/data-factory/tutorial-incremental-copy-overview#slowly-changing-data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "094bba44-ae7f-4bc9-a2db-b2e32e21d117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Before applying the SCD Type 1 merge, let's inspect the data in the target table for a specific franchiseID\n",
    "display(spark.sql(\"select * from workspace.de_practice_target.sales where franchiseID='3000001'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea0b0482-5621-4329-a4e8-058514206e39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import current_timestamp, col\n",
    "\n",
    "# Static configuration\n",
    "table_name = \"workspace.de_practice_target.sales\"\n",
    "key_column = \"franchiseID\"\n",
    "timestamp_column = \"ModifiedDate\"\n",
    "hash_column = \"RowHash\"\n",
    "created_column = \"CreatedDate\"\n",
    "\n",
    "# Reference Delta table\n",
    "target_table = DeltaTable.forName(spark, table_name)\n",
    "\n",
    "# Aliases\n",
    "src = SourceDf.alias(\"src\")\n",
    "tgt = target_table.alias(\"tgt\")\n",
    "\n",
    "# Columns to update (exclude key, timestamp, and created date)\n",
    "columns_to_update = [\n",
    "    col_name for col_name in SourceDf.columns \n",
    "    if col_name not in [key_column, timestamp_column, created_column]\n",
    "]\n",
    "\n",
    "# Construct SET dictionary for update\n",
    "set_dict = {col_name: col(f\"src.{col_name}\") for col_name in columns_to_update}\n",
    "set_dict[timestamp_column] = current_timestamp()  # Add ModifiedDate explicitly\n",
    "\n",
    "# Perform SCD Type 1 MERGE\n",
    "tgt.merge(\n",
    "    src,\n",
    "    f\"tgt.{key_column} = src.{key_column}\"\n",
    ").whenMatchedUpdate(\n",
    "    condition=col(f\"src.{hash_column}\") != col(f\"tgt.{hash_column}\"),\n",
    "    set=set_dict\n",
    ").whenNotMatchedInsertAll().execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cbc4d17-ae2f-4fca-8d9e-61a535d620d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Inspect the target table data for a specific franchiseID after applying the SCD Type 1 merge\n",
    "display(spark.sql(\"select * from workspace.de_practice_target.sales where franchiseID='3000001'\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SCD_Type- 1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
